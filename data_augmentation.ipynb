{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162ec181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/username/.local/lib/python3.9/site-packages (4.19.1)\n",
      "Requirement already satisfied: sentencepiece in /home/username/.local/lib/python3.9/site-packages (0.1.96)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/username/.local/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/username/.local/lib/python3.9/site-packages (from transformers) (1.19.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/username/.local/lib/python3.9/site-packages (from transformers) (0.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/username/.local/lib/python3.9/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/username/.local/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/username/.local/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/username/.local/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/username/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/username/.local/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sacremoses in /home/username/.local/lib/python3.9/site-packages (0.0.53)\n",
      "Requirement already satisfied: regex in /home/username/.local/lib/python3.9/site-packages (from sacremoses) (2022.4.24)\n",
      "Requirement already satisfied: joblib in /home/username/.local/lib/python3.9/site-packages (from sacremoses) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /home/username/.local/lib/python3.9/site-packages (from sacremoses) (4.62.3)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from sacremoses) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json from cache at /home/username/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
      "Model config PegasusConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 60,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/pytorch_model.bin from cache at /home/username/.cache/huggingface/transformers/227d9f57dd37c1f4f5be77ccf5f896e7551ec64db897d21c4613d235eb9cc73a.9e93d391568a0e6e2b8408cd2311ebfa97682e0e0bd8b83a631ab7ad40e93905\n",
      "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
      "\n",
      "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at tuner007/pegasus_paraphrase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
      "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/spiece.model from cache at /home/username/.cache/huggingface/transformers/b3949a7257f9b4eaaf4f7785be079d89e4fec7d1c3763a58e6a2743635877d1f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n",
      "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/special_tokens_map.json from cache at /home/username/.cache/huggingface/transformers/1ff5597b098cfe2ee6d3b0c4b3e94e549fcb86f2e033146119d1591f6e4c4166.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
      "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/tokenizer_config.json from cache at /home/username/.cache/huggingface/transformers/3f72dece4d3fcab1480f78a2c2a1f6ab591bb9b77ec8b049f8faa418bd50526d.f96255d0af339b1faae306ed2925a98f5266a4ebbf793a8bca5107f6e0f876dd\n",
      "loading configuration file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json from cache at /home/username/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"tuner007/pegasus_paraphrase\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 60,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json from cache at /home/username/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"tuner007/pegasus_paraphrase\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 60,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://arxiv.org/pdf/1912.08777.pdf\n",
    "!pip install transformers sentencepiece\n",
    "!pip install sacremoses\n",
    "from transformers import *\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "tokenizer = PegasusTokenizerFast.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "\n",
    "def get_paraphrased_sentences(model, tokenizer, sentence, num_return_sequences=5, num_beams=5):\n",
    "  # tokenize the text to be form of a list of token IDs\n",
    "  inputs = tokenizer([sentence], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "  # generate the paraphrased sentences\n",
    "  outputs = model.generate(\n",
    "    **inputs,\n",
    "    num_beams=num_beams,\n",
    "    num_return_sequences=num_return_sequences,\n",
    "  )\n",
    "  # decode the generated sentences using the tokenizer to get them back to text\n",
    "  return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f429dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "runs = 2\n",
    "\n",
    "pdf_files = ['Cancellation', 'SecureTripBudget','SecureTripClassic', 'SecureTripPremium', 'SecureTripPremiumPlus', 'TravelProtectionClassic', 'TravelProtectionPremium', 'TravelProtectionPremiumPlus' ]\n",
    "for j in range(len(pdf_files)):\n",
    "    with open('./adobe_csv/'+pdf_files[j]+'.csv', newline='') as csvfile:\n",
    "        reader = list(csv.reader(csvfile, quoting=csv.QUOTE_ALL, skipinitialspace=True))        \n",
    "        \n",
    "    augmentation = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i ==0 :\n",
    "            header = row\n",
    "            continue\n",
    "\n",
    "        questions = get_paraphrased_sentences(model, tokenizer, row[1], num_beams=runs, num_return_sequences=runs)\n",
    "        answers = get_paraphrased_sentences(model, tokenizer, row[2], num_beams=runs, num_return_sequences=runs)\n",
    "        augmentation.append(row)\n",
    "        for i in range(runs):\n",
    "            augmentation.append([row[0], questions[i], answers[i], row[3]])\n",
    "    \n",
    "    with open('./adobe_csv_augmentation/'+pdf_files[j]+'_augmentation.csv', mode= 'w',newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8e4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
